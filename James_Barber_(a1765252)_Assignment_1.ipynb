{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "058a819f-cbe9-4268-bed5-5f104d532240",
   "metadata": {},
   "source": [
    "<h1>James Barber (a1765252) Assignment 1 Code <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e26862c-d9ae-4a63-b164-0f2fba07aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d24df-e76d-471b-8793-6df57a86273b",
   "metadata": {},
   "source": [
    "<h1>Data Collation and Preperation<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ca7aed-c216-4d53-bf3a-16fe89df0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      " [[-0.294118    0.487437    0.180328   ...  0.00149028 -0.53117\n",
      "  -0.0333333 ]\n",
      " [-0.882353   -0.145729    0.0819672  ... -0.207153   -0.766866\n",
      "  -0.666667  ]\n",
      " [-0.0588235   0.839196    0.0491803  ... -0.305514   -0.492741\n",
      "  -0.633333  ]\n",
      " ...\n",
      " [-0.411765    0.21608     0.180328   ... -0.219076   -0.857387\n",
      "  -0.7       ]\n",
      " [-0.882353    0.266332   -0.0163934  ... -0.102832   -0.768574\n",
      "  -0.133333  ]\n",
      " [-0.882353   -0.0653266   0.147541   ... -0.0938897  -0.797609\n",
      "  -0.933333  ]]\n",
      "Labels:\n",
      " [-1  1 -1  1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1  1  1 -1 -1\n",
      " -1 -1 -1  1  1  1  1 -1  1  1  1  1  1 -1 -1 -1  1  1  1 -1  1 -1  1  1\n",
      " -1  1  1  1  1 -1  1  1 -1  1  1  1  1 -1  1  1 -1  1 -1  1  1  1 -1  1\n",
      " -1  1  1  1  1  1 -1  1  1  1  1  1 -1  1  1  1 -1  1  1  1  1 -1  1  1\n",
      "  1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1 -1 -1  1  1 -1 -1 -1  1  1  1\n",
      " -1  1  1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1 -1\n",
      "  1  1  1  1  1  1  1  1 -1  1 -1 -1  1  1  1 -1  1  1  1  1 -1 -1  1  1\n",
      "  1  1 -1 -1  1  1  1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1 -1 -1 -1  1  1\n",
      " -1 -1  1 -1  1 -1 -1 -1  1  1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1 -1\n",
      " -1  1 -1 -1 -1 -1  1  1  1  1  1 -1  1  1 -1 -1  1  1  1 -1 -1 -1 -1  1\n",
      "  1  1 -1 -1  1 -1  1  1  1  1  1  1  1  1 -1 -1  1  1  1 -1  1 -1  1  1\n",
      " -1  1 -1  1  1 -1 -1  1  1  1  1  1 -1  1  1  1 -1  1  1 -1 -1  1  1 -1\n",
      "  1  1  1 -1 -1 -1  1  1 -1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1 -1  1  1\n",
      " -1  1 -1  1  1 -1  1 -1  1 -1 -1 -1  1  1 -1  1 -1  1  1  1 -1  1  1  1\n",
      "  1 -1 -1 -1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1 -1 -1  1 -1\n",
      " -1  1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1 -1  1  1 -1  1  1  1  1  1\n",
      "  1  1 -1 -1 -1  1  1 -1  1  1 -1  1  1 -1  1 -1 -1  1 -1  1 -1  1 -1  1\n",
      " -1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1  1\n",
      "  1  1  1 -1  1  1  1  1 -1  1  1 -1 -1 -1  1  1 -1  1  1 -1  1  1  1 -1\n",
      "  1  1 -1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1 -1  1  1  1\n",
      " -1  1  1  1 -1 -1  1  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1  1 -1  1\n",
      "  1  1 -1  1  1  1 -1  1  1  1  1 -1 -1  1  1  1  1  1  1 -1  1  1  1  1\n",
      "  1  1  1  1  1  1  1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1 -1 -1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1\n",
      "  1 -1  1 -1 -1  1  1  1 -1  1 -1  1 -1  1 -1  1 -1  1  1 -1  1  1 -1  1\n",
      "  1  1  1 -1 -1  1 -1  1  1  1  1 -1 -1  1 -1  1  1  1 -1 -1  1  1  1  1\n",
      "  1  1  1  1  1  1 -1  1  1  1  1 -1  1  1 -1  1  1  1 -1  1  1  1 -1 -1\n",
      " -1  1  1  1  1  1  1 -1  1  1  1 -1  1 -1 -1 -1 -1  1 -1 -1  1  1  1  1\n",
      "  1  1  1 -1 -1  1 -1  1  1 -1  1 -1  1  1  1  1  1 -1  1 -1  1 -1  1 -1\n",
      " -1  1  1  1  1 -1 -1  1  1  1 -1  1 -1 -1  1  1 -1  1  1 -1 -1  1  1 -1\n",
      "  1  1 -1  1  1  1  1  1  1  1 -1 -1 -1  1  1  1  1  1  1 -1 -1  1  1 -1\n",
      "  1  1 -1  1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1 -1  1 -1  1  1  1  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "def readData(filePath):\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(filePath, 'r') as file:\n",
    "        for line in file:\n",
    "            elements = line.strip().split()\n",
    "            label = int(elements[0])\n",
    "            y.append(label)\n",
    "\n",
    "            featureVector = np.zeros(8)\n",
    "\n",
    "            for feature in elements[1:]:\n",
    "                index, value = feature.split(\":\")\n",
    "                featureVector[int(index) - 1] = float(value)\n",
    "\n",
    "            X.append(featureVector)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "filePath = \"C:/Users/James\\Desktop/University/T32024/Deep Learning\\Assignment 1/diabetes_scale.txt\" \n",
    "X, y = readData(filePath)\n",
    "\n",
    "print(\"Features:\\n\", X)\n",
    "print(\"Labels:\\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1302d-b7ab-40ff-aa05-577b2eeec77c",
   "metadata": {},
   "source": [
    "<h1>Test and experiments<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2a3e69-f560-4051-afc6-9294741eee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Observations: 614\n",
      "Testing observations: 154\n",
      "Accuracy:0.741042345276873\n",
      "\n",
      "Train Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.80      0.68       213\n",
      "           1       0.87      0.71      0.78       401\n",
      "\n",
      "    accuracy                           0.74       614\n",
      "   macro avg       0.73      0.75      0.73       614\n",
      "weighted avg       0.77      0.74      0.75       614\n",
      "\n",
      "Accuracy:0.7467532467532467\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.73      0.67        55\n",
      "           1       0.83      0.76      0.79        99\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#This functin implements the activation function, a step function that uses the sign of x to determine if the observation is a positive or negative class\n",
    "def activationFunction(x):\n",
    "    return np.where(x >= 0, 1, -1)\n",
    "\n",
    "#This function is used to train the model\n",
    "def train(X, y, learningRate, epochs):\n",
    "    #find the number of samples and features\n",
    "    nSamples, nFeatures = X.shape\n",
    "\n",
    "    #INitialise the weights and set to 0\n",
    "    weights = np.zeros(nFeatures)\n",
    "\n",
    "    #Initialise the bias\n",
    "    bias = 0\n",
    "\n",
    "    #For the defined number of epochs, train the model by adjusting the weights and bias to optimise the decision boundary\n",
    "    for epoch in range(epochs):\n",
    "        for i, x_i in enumerate(X):\n",
    "            linearComponent = np.dot(x_i, weights) + bias\n",
    "            y_pred = activationFunction(linearComponent)\n",
    "            adjustment = learningRate * (y[i] - y_pred)\n",
    "            weights = weights + (adjustment * x_i)\n",
    "            bias = bias + adjustment\n",
    "    return weights, bias\n",
    "\n",
    "#This function is used for predeiction. It is passed the trained weights and bias in order to calculate the linear componenent, which is passed ot the activation function\n",
    "def predict(X, weights, bias):\n",
    "    linearComponent = np.dot(X, weights) + bias\n",
    "    y_pred = activationFunction(linearComponent)\n",
    "    return y_pred\n",
    "\n",
    "#This function splits the data into train and test sets, trains the model, then tests it, reporting back the metrics\n",
    "\n",
    "def main(X, y, test_size=0.2, learning_rate=0.01, epochs=1000, random_state=42):\n",
    "    # split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=1\n",
    "    )\n",
    "    \n",
    "    print(\"Training Observations: \" + str(len(X_train)))\n",
    "    print(\"Testing observations: \" + str(len(X_test)))\n",
    "    \n",
    "    weights, bias = train(X_train, y_train, learning_rate, epochs)\n",
    "    \n",
    "    y_train_pred = predict(X_train, weights, bias)\n",
    "    y_test_pred = predict(X_test, weights, bias)\n",
    "\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    classification_rep = classification_report(y_train, y_train_pred)\n",
    "\n",
    "    print(\"Accuracy:\" + str(accuracy))\n",
    "    print(\"\\nTrain Classification Report:\\n\", classification_rep)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    classification_rep = classification_report(y_test, y_test_pred)\n",
    "\n",
    "    print(\"Accuracy:\" + str(accuracy))\n",
    "    print(\"\\nTest Classification Report:\\n\", classification_rep)\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "main(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c6d83-1407-477e-98b2-857d672319f0",
   "metadata": {},
   "source": [
    "<h1>Random Forest Experiment<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d5ac1c-688c-4b31-b2d7-581d449b0c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7987012987012987\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.65      0.70        55\n",
      "           1       0.82      0.88      0.85        99\n",
      "\n",
      "    accuracy                           0.80       154\n",
      "   macro avg       0.79      0.77      0.77       154\n",
      "weighted avg       0.80      0.80      0.80       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#I used the scikit learn library to quickly implement a basic random forest model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42) \n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classificationReport = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\" + str(accuracy))\n",
    "print(\"\\nClassification Report:\\n\", classificationReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a510f-32cd-4379-a283-850dcee1dd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
